{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65b52cb4",
   "metadata": {},
   "source": [
    "# 02 Transformations and Actions\n",
    "\n",
    "- Read a CSV file to a dataframe using schema inference\n",
    "- Transform dataframe's columns (modify data types)\n",
    "- Execute SQL queries using spark.sql()\n",
    "- Use dataframe API to get the same results as SQL queries \n",
    "  - Perform transformations and actions\n",
    "- Identify the role of the Catalyst optimizer for queries optimization \n",
    "  - SQL/DataFrame -> unresolved logical plan -> resolved logical plan -> optimized logical plan -> physical plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3f5594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a spark session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46150e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create dataframe from csv file at \"../../datasets/sf-fire-calls.csv\", with header, infer the schema by the values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f416e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Count the number of rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf54d3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Print the inferred schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef81e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Display columns: AvailableDtTm, ZipCode and CallDate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4711884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Make the following transformations\n",
    "# transform column AvailableDtTm to timestamp using pyspark.sql.functions.to_timestamp() \n",
    "# transform column CallDate to date using pyspark.sql.functions.to_date()\n",
    "# transform column Zipcode to string using pyspark.sql.functions.expr()\n",
    "# see https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9855442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Save dataframe to table \"sf_fire_calls\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d828e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Load data from table \"sf_fire_calls\" and print the number of rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84889e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Execute an sql using spark.sql that finds the 5 ZipCodes with the higher number of calls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574e322c",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71117a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Issue using spark.sql() an SQL command for the following query: \n",
    "# Among all records with a CallType that is not NULL, \n",
    "# find the three CallType, Zipcode combinations \n",
    "# that occur most often, and report how many times each occurs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54bb522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Create equivalent result with the previous SQL command using the Spark DataFrame API. \n",
    "# Create intermediate dataframes using 1 or 2 method invocations at a time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b89ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Produce the same result using the composable API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b677321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Call explain for the produced final dataframe (CATALYST OPTIMIZER)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092c8159",
   "metadata": {},
   "source": [
    "![](https://www.databricks.com/wp-content/uploads/2018/05/Catalyst-Optimizer-diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d258aef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. List all different call types that are recorded in the sf_fire_calls\n",
    "# table, ignoring entries where the call type is not specified (i.e. NULL).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2980340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Ditto using Dataframe API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23388a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. Using SQL answer: \n",
    "# What neighborhoods had the worst response time on average in 2018?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9624ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. Ditto using Dataframe API\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
