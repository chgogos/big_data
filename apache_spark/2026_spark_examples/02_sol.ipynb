{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65b52cb4",
   "metadata": {},
   "source": [
    "# 02 Transformations and Actions\n",
    "\n",
    "- Read a CSV file to a dataframe using schema inference\n",
    "- Transform dataframe's columns (modify data types)\n",
    "- Execute SQL queries using spark.sql()\n",
    "- Use dataframe API to get the same results as SQL queries \n",
    "  - Perform transformations and actions\n",
    "- Identify the role of the Catalyst optimizer for queries optimization \n",
    "  - SQL/DataFrame -> unresolved logical plan -> resolved logical plan -> optimized logical plan -> physical plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef3f5594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.0.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Create a spark session\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46150e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|CallNumber|UnitID|IncidentNumber|        CallType|  CallDate| WatchDate|CallFinalDisposition|       AvailableDtTm|             Address|City|Zipcode|Battalion|StationArea| Box|OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|        Neighborhood|            Location|        RowID|    Delay|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|  20110016|   T13|       2003235|  Structure Fire|01/11/2002|01/10/2002|               Other|01/11/2002 01:51:...|2000 Block of CAL...|  SF|  94109|      B04|         38|3362|               3|       3|            3|  false|         NULL|        1|   TRUCK|                         2|                     4|                 5|     Pacific Heights|(37.7895840679362...|020110016-T13|     2.95|\n",
      "|  20110022|   M17|       2003241|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 03:01:...|0 Block of SILVER...|  SF|  94124|      B10|         42|6495|               3|       3|            3|   true|         NULL|        1|   MEDIC|                         1|                    10|                10|Bayview Hunters P...|(37.7337623673897...|020110022-M17|      4.7|\n",
      "|  20110023|   M41|       2003242|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 02:39:...|MARKET ST/MCALLIS...|  SF|  94102|      B03|         01|1455|               3|       3|            3|   true|         NULL|        1|   MEDIC|                         2|                     3|                 6|          Tenderloin|(37.7811772186856...|020110023-M41|2.4333334|\n",
      "|  20110032|   E11|       2003250|    Vehicle Fire|01/11/2002|01/10/2002|               Other|01/11/2002 04:16:...|APPLETON AV/MISSI...|  SF|  94110|      B06|         32|5626|               3|       3|            3|  false|         NULL|        1|  ENGINE|                         1|                     6|                 9|      Bernal Heights|(37.7388432849018...|020110032-E11|      1.5|\n",
      "|  20110043|   B04|       2003259|          Alarms|01/11/2002|01/10/2002|               Other|01/11/2002 06:01:...|1400 Block of SUT...|  SF|  94109|      B04|         03|3223|               3|       3|            3|  false|         NULL|        1|   CHIEF|                         2|                     4|                 2|    Western Addition|(37.7872890372638...|020110043-B04|3.4833333|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# 2. Create dataframe from csv file at \"../../datasets/sf-fire-calls.csv\", with header, infer the schema by the values\n",
    "\n",
    "raw_fire_df = (\n",
    "    spark.read.format(\"csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .load(\"../../datasets/sf-fire-calls.csv\")\n",
    ")\n",
    "\n",
    "raw_fire_df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f416e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175296"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Count the number of rows\n",
    "\n",
    "raw_fire_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf54d3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Print the inferred schema\n",
    "\n",
    "raw_fire_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef81e818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+----------+-------+\n",
      "|AvailableDtTm         |CallDate  |ZipCode|\n",
      "+----------------------+----------+-------+\n",
      "|01/11/2002 01:51:44 AM|01/11/2002|94109  |\n",
      "|01/11/2002 03:01:18 AM|01/11/2002|94124  |\n",
      "|01/11/2002 02:39:50 AM|01/11/2002|94102  |\n",
      "|01/11/2002 04:16:46 AM|01/11/2002|94110  |\n",
      "|01/11/2002 06:01:58 AM|01/11/2002|94109  |\n",
      "|01/11/2002 08:03:26 AM|01/11/2002|94105  |\n",
      "|01/11/2002 09:46:44 AM|01/11/2002|94112  |\n",
      "|01/11/2002 09:58:53 AM|01/11/2002|94102  |\n",
      "|01/11/2002 12:06:57 PM|01/11/2002|94115  |\n",
      "|01/11/2002 01:08:40 PM|01/11/2002|94114  |\n",
      "|01/11/2002 03:31:02 PM|01/11/2002|94110  |\n",
      "|01/11/2002 02:59:04 PM|01/11/2002|94112  |\n",
      "|01/11/2002 04:22:49 PM|01/11/2002|94109  |\n",
      "|01/11/2002 04:18:33 PM|01/11/2002|94121  |\n",
      "|01/11/2002 04:09:08 PM|01/11/2002|94110  |\n",
      "|01/11/2002 04:09:08 PM|01/11/2002|94110  |\n",
      "|01/11/2002 04:09:08 PM|01/11/2002|94110  |\n",
      "|01/11/2002 04:34:23 PM|01/11/2002|94116  |\n",
      "|01/11/2002 04:51:31 PM|01/11/2002|94118  |\n",
      "|01/11/2002 04:51:12 PM|01/11/2002|94118  |\n",
      "+----------------------+----------+-------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# 5. Display columns: AvailableDtTm, ZipCode and CallDate\n",
    "\n",
    "raw_fire_df.select(\"AvailableDtTm\", \"CallDate\", \"ZipCode\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4711884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: date (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: timestamp (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- ZipCode: string (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. Make the following transformations\n",
    "# transform column AvailableDtTm to timestamp using pyspark.sql.functions.to_timestamp() \n",
    "# transform column CallDate to date using pyspark.sql.functions.to_date()\n",
    "# transform column Zipcode to string using pyspark.sql.functions.expr()\n",
    "# see https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html\n",
    "\n",
    "from pyspark.sql.functions import to_timestamp, to_date, expr\n",
    "\n",
    "fire_df = raw_fire_df.withColumns({\n",
    "    \"AvailableDtTm\": to_timestamp(\"AvailableDtTm\", \"MM/dd/yyyy hh:mm:ss a\"),\n",
    "    \"ZipCode\": expr(\"cast(Zipcode as string)\"),\n",
    "    \"CallDate\": to_date(\"CallDate\", \"MM/dd/yyyy\")\n",
    "})\n",
    "\n",
    "fire_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9855442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Save dataframe to table \"sf_fire_calls\"\n",
    "\n",
    "fire_df.write.mode(\"overwrite\").saveAsTable(\"sf_fire_calls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d828e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175296"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Load data from table \"sf_fire_calls\" and print the number of rows\n",
    "\n",
    "fire_df2 = spark.table(\"sf_fire_calls\")\n",
    "fire_df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84889e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Execute an sql using spark.sql that finds the 5 ZipCodes with the higher number of calls\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT ZipCode, COUNT(*) AS cnt\n",
    "    FROM sf_fire_calls\n",
    "    GROUP BY ZipCode\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574e322c",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71117a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Issue using spark.sql() an SQL command for the following query: \n",
    "# Among all records with a CallType that is not NULL, \n",
    "# find the three CallType, Zipcode combinations \n",
    "# that occur most often, and report how many times each occurs.\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "select CallType, Zipcode, count(*) as count\n",
    "from sf_fire_calls\n",
    "where CallType is not null\n",
    "group by CallType, Zipcode\n",
    "order by count desc\n",
    "limit 3\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54bb522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Create equivalent result with the previous SQL command using the Spark DataFrame API. \n",
    "# Create intermediate dataframes using 1 or 2 method invocations at a time.\n",
    "\n",
    "df1 = fire_df.select(\"CallType\", \"Zipcode\")\n",
    "df2 = df1.where(\"CallType is not null\")\n",
    "df3 = df2.groupBy(\"CallType\", \"Zipcode\").count()\n",
    "df4 = df3.orderBy(\"count\", ascending=False)\n",
    "df5 = df4.limit(3)\n",
    "df5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b89ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Produce the same result using the composable API\n",
    "\n",
    "result_df = (\n",
    "    fire_df.select(\"CallType\", \"Zipcode\")\n",
    "            .where(\"CallType is not null\")\n",
    "            .groupBy(\"CallType\", \"Zipcode\")\n",
    "            .count()\n",
    "            .orderBy(\"count\", ascending=False)\n",
    "            .limit(3)\n",
    ")\n",
    "\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b677321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Call explain for the produced final dataframe (CATALYST OPTIMIZER)\n",
    "\n",
    "result_df.explain(mode=\"extended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092c8159",
   "metadata": {},
   "source": [
    "![](https://www.databricks.com/wp-content/uploads/2018/05/Catalyst-Optimizer-diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d258aef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. List all different call types that are recorded in the sf_fire_calls\n",
    "# table, ignoring entries where the call type is not specified (i.e. NULL).\n",
    "\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "select distinct CallType as distinct_call_types\n",
    "from sf_fire_calls\n",
    "where CallType is not null\n",
    "\"\"\"\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2980340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Ditto using Dataframe API\n",
    "\n",
    "(\n",
    "    fire_df.where(\"CallType is not null\")\n",
    "    .selectExpr(\"CallType as distinct_call_type\")\n",
    "    .distinct()\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23388a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. Using SQL answer: \n",
    "# What neighborhoods had the worst response time on average in 2018?\n",
    "\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT Neighborhood, AVG(Delay) AS avg_delay\n",
    "    FROM sf_fire_calls\n",
    "    WHERE year(CallDate) = 2018\n",
    "    GROUP BY Neighborhood\n",
    "    ORDER BY avg_delay desc;\n",
    "    \"\"\"\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9624ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. Ditto using Dataframe API\n",
    "\n",
    "from pyspark.sql.functions import year, avg, col\n",
    "\n",
    "(\n",
    "    spark.table(\"sf_fire_calls\")\n",
    "         .where(year(col(\"CallDate\")) == 2018)\n",
    "         .groupBy(\"Neighborhood\")\n",
    "         .agg(avg(\"Delay\").alias(\"avg_delay\"))\n",
    "         .orderBy(col(\"avg_delay\").desc())\n",
    "         .show(truncate=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97bae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. Alternatively\n",
    "\n",
    "from pyspark.sql.functions import year, avg, col\n",
    "\n",
    "(\n",
    "    spark.table(\"sf_fire_calls\")\n",
    "         .filter(year(col(\"CallDate\")) == 2018)\n",
    "         .groupBy(\"Neighborhood\")\n",
    "         .agg(avg(\"Delay\").alias(\"avg_delay\"))\n",
    "         .orderBy(col(\"avg_delay\").desc())\n",
    "         .show(truncate=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a345a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
