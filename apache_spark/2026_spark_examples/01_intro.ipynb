{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e919ac09",
   "metadata": {},
   "source": [
    "# 01_intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d14203a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.1.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a spark session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark_session = SparkSession.builder.getOrCreate()\n",
    "spark_session.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acd99715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/02/01 01:40:22 WARN FileSystem: Cannot load filesystem\n",
      "java.util.ServiceConfigurationError: org.apache.hadoop.fs.FileSystem: Provider org.apache.hadoop.fs.viewfs.ViewFileSystem could not be instantiated\n",
      "\tat java.base/java.util.ServiceLoader.fail(ServiceLoader.java:582)\n",
      "\tat java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:809)\n",
      "\tat java.base/java.util.ServiceLoader$ProviderImpl.get(ServiceLoader.java:725)\n",
      "\tat java.base/java.util.ServiceLoader$3.next(ServiceLoader.java:1397)\n",
      "\tat org.apache.hadoop.fs.FileSystem.loadFileSystems(FileSystem.java:3525)\n",
      "\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3562)\n",
      "\tat org.apache.hadoop.fs.FsUrlStreamHandlerFactory.<init>(FsUrlStreamHandlerFactory.java:77)\n",
      "\tat org.apache.spark.sql.internal.SharedState$.liftedTree2$1(SharedState.scala:209)\n",
      "\tat org.apache.spark.sql.internal.SharedState$.org$apache$spark$sql$internal$SharedState$$setFsUrlStreamHandlerFactory(SharedState.scala:208)\n",
      "\tat org.apache.spark.sql.internal.SharedState.<init>(SharedState.scala:56)\n",
      "\tat org.apache.spark.sql.classic.SparkSession.$anonfun$sharedState$1(SparkSession.scala:176)\n",
      "\tat scala.Option.getOrElse(Option.scala:201)\n",
      "\tat org.apache.spark.sql.classic.SparkSession.sharedState$lzycompute(SparkSession.scala:176)\n",
      "\tat org.apache.spark.sql.classic.SparkSession.sharedState(SparkSession.scala:175)\n",
      "\tat org.apache.spark.sql.classic.SparkSession.$anonfun$sessionState$2(SparkSession.scala:187)\n",
      "\tat scala.Option.getOrElse(Option.scala:201)\n",
      "\tat org.apache.spark.sql.classic.SparkSession.sessionState$lzycompute(SparkSession.scala:185)\n",
      "\tat org.apache.spark.sql.classic.SparkSession.sessionState(SparkSession.scala:182)\n",
      "\tat org.apache.spark.sql.classic.SparkSession.$anonfun$new$3(SparkSession.scala:129)\n",
      "\tat scala.Option.map(Option.scala:242)\n",
      "\tat org.apache.spark.sql.classic.SparkSession.$anonfun$new$1(SparkSession.scala:129)\n",
      "\tat org.apache.spark.sql.internal.SQLConf$.get(SQLConf.scala:238)\n",
      "\tat org.apache.spark.sql.internal.SQLConf$.$anonfun$new$1(SQLConf.scala:188)\n",
      "\tat org.apache.spark.sql.internal.SqlApiConf$.get(SqlApiConf.scala:79)\n",
      "\tat org.apache.spark.sql.catalyst.parser.AbstractParser.conf(parsers.scala:101)\n",
      "\tat org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.parser.AbstractParser.parseTableSchema(parsers.scala:52)\n",
      "\tat org.apache.spark.sql.types.StructType$.fromDDL(StructType.scala:547)\n",
      "\tat org.apache.spark.sql.api.python.PythonSQLUtils$.ddlToJson(PythonSQLUtils.scala:155)\n",
      "\tat org.apache.spark.sql.api.python.PythonSQLUtils.ddlToJson(PythonSQLUtils.scala)\n",
      "\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1575)\n",
      "Caused by: java.lang.UnsupportedOperationException: getSubject is supported only if a security manager is allowed\n",
      "\tat java.base/javax.security.auth.Subject.getSubject(Subject.java:347)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:588)\n",
      "\tat org.apache.hadoop.fs.viewfs.ViewFileSystem.<init>(ViewFileSystem.java:281)\n",
      "\tat java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:501)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:485)\n",
      "\tat java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:785)\n",
      "\t... 38 more\n",
      "26/02/01 01:40:22 WARN SharedState: Cannot qualify the warehouse path, leaving it unqualified.\n",
      "java.lang.UnsupportedOperationException: getSubject is supported only if a security manager is allowed\n",
      "\tat java.base/javax.security.auth.Subject.getSubject(Subject.java:347)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:588)\n",
      "\tat org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3888)\n",
      "\tat org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3878)\n",
      "\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3666)\n",
      "\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:557)\n",
      "\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:366)\n",
      "\tat org.apache.spark.sql.internal.SharedState$.qualifyWarehousePath(SharedState.scala:302)\n",
      "\tat org.apache.spark.sql.internal.SharedState.liftedTree1$1(SharedState.scala:82)\n",
      "\tat org.apache.spark.sql.internal.SharedState.<init>(SharedState.scala:81)\n",
      "\tat org.apache.spark.sql.classic.SparkSession.$anonfun$sharedState$1(SparkSession.scala:176)\n",
      "\tat scala.Option.getOrElse(Option.scala:201)\n",
      "\tat org.apache.spark.sql.classic.SparkSession.sharedState$lzycompute(SparkSession.scala:176)\n",
      "\tat org.apache.spark.sql.classic.SparkSession.sharedState(SparkSession.scala:175)\n",
      "\tat org.apache.spark.sql.classic.SparkSession.$anonfun$sessionState$2(SparkSession.scala:187)\n",
      "\tat scala.Option.getOrElse(Option.scala:201)\n",
      "\tat org.apache.spark.sql.classic.SparkSession.sessionState$lzycompute(SparkSession.scala:185)\n",
      "\tat org.apache.spark.sql.classic.SparkSession.sessionState(SparkSession.scala:182)\n",
      "\tat org.apache.spark.sql.classic.SparkSession.$anonfun$new$3(SparkSession.scala:129)\n",
      "\tat scala.Option.map(Option.scala:242)\n",
      "\tat org.apache.spark.sql.classic.SparkSession.$anonfun$new$1(SparkSession.scala:129)\n",
      "\tat org.apache.spark.sql.internal.SQLConf$.get(SQLConf.scala:238)\n",
      "\tat org.apache.spark.sql.internal.SQLConf$.$anonfun$new$1(SQLConf.scala:188)\n",
      "\tat org.apache.spark.sql.internal.SqlApiConf$.get(SqlApiConf.scala:79)\n",
      "\tat org.apache.spark.sql.catalyst.parser.AbstractParser.conf(parsers.scala:101)\n",
      "\tat org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:70)\n",
      "\tat org.apache.spark.sql.catalyst.parser.AbstractParser.parseTableSchema(parsers.scala:52)\n",
      "\tat org.apache.spark.sql.types.StructType$.fromDDL(StructType.scala:547)\n",
      "\tat org.apache.spark.sql.api.python.PythonSQLUtils$.ddlToJson(PythonSQLUtils.scala:155)\n",
      "\tat org.apache.spark.sql.api.python.PythonSQLUtils.ddlToJson(PythonSQLUtils.scala)\n",
      "\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1575)\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe\n",
    "from datetime import date\n",
    "\n",
    "students_schema = 'id long, name string, enrolment_date date, gpa double'\n",
    "\n",
    "students_data = [(1, \"Nikos Zikos\", date(2025, 9, 1), 7.7),\n",
    "                 (2, \"Maria Pappa\", date(2025, 9, 2), 6.7),\n",
    "                 (2, \"Petros Kokkinos\", date(2025, 9, 1), 7.6)]\n",
    "\n",
    "students_df = spark_session.createDataFrame(students_data, students_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea0104b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
